{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "\n",
    "Business Case 1<a class=\"anchor\"><a id='toc'></a></b><br>\n",
    "* [<font color='#E8800A'>Import Libraries</font>](#first-bullet)<br>\n",
    "- [<font color='#E8800A'>Extracting Time Series Data</font>](#second-bullet)<br>\n",
    "- [<font color='#E8800A'>Data Exploration</font>](#third-bullet)<br>\n",
    "- [<font color='#E8800A'>Missing Cases</font>](#fourth-bullet)<br>\n",
    "- [<font color='#E8800A'>Encoding Categorical Features</font>](#fifth-bullet)<br>\n",
    "- [<font color='#E8800A'>Data Partition</font>](#sixth-bullet)<br>\n",
    "- [<font color='#E8800A'>Outliers</font>](#seventh-bullet)<br>\n",
    "- [<font color='#E8800A'>Normalization</font>](#eighth-bullet)<br>\n",
    "- [<font color='#E8800A'>Classification</font>](#nineth-bullet)<br>\n",
    "- [<font color='#E8800A'>Features Selection</font>](#tenth-bullet)<br>\n",
    "- [<font color='#E8800A'>Ballancing Dataset</font>](#eleventh-bullet)<br>\n",
    "- [<font color='#E8800A'>Tuning Models</font>](#twelveth-bullet)<br>\n",
    "- [<font color='#E8800A'>Models Performance Comparison</font>](#thirteenth-bullet)<br>\n",
    "- [<font color='#E8800A'>Testing the Model</font>](#fourteenth-bullet)<br>\n",
    "- [<font color='#E8800A'>Lift Curve</font>](#fifteenth-bullet)<br>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Import Libraries</font> <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.base import clone\n",
    "\n",
    "# imports for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from itertools import product\n",
    "from pandas_profiling import ProfileReport\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "import matplotlib.cm as cm\n",
    "sns.set()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from collections import Counter\n",
    "from scikitplot.metrics import plot_cumulative_gain, plot_lift_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsCanceled</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>ArrivalDateWeekNumber</th>\n",
       "      <th>ArrivalDateDayOfMonth</th>\n",
       "      <th>StaysInWeekendNights</th>\n",
       "      <th>StaysInWeekNights</th>\n",
       "      <th>Adults</th>\n",
       "      <th>Children</th>\n",
       "      <th>Babies</th>\n",
       "      <th>PreviousCancellations</th>\n",
       "      <th>...</th>\n",
       "      <th>x5_HB</th>\n",
       "      <th>x5_SC</th>\n",
       "      <th>x6_1</th>\n",
       "      <th>x7_B</th>\n",
       "      <th>x7_C</th>\n",
       "      <th>x7_D</th>\n",
       "      <th>x7_E</th>\n",
       "      <th>x7_F</th>\n",
       "      <th>x7_G</th>\n",
       "      <th>x7_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.139905</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.103339</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.146264</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.158983</td>\n",
       "      <td>27</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79325</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036566</td>\n",
       "      <td>35</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79327</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79328</th>\n",
       "      <td>0</td>\n",
       "      <td>0.173291</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79329</th>\n",
       "      <td>0</td>\n",
       "      <td>0.325914</td>\n",
       "      <td>35</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79330 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IsCanceled  LeadTime  ArrivalDateWeekNumber  ArrivalDateDayOfMonth  \\\n",
       "0               0  0.009539                     27               0.000000   \n",
       "1               1  0.139905                     27               0.000000   \n",
       "2               1  0.103339                     27               0.000000   \n",
       "3               1  0.146264                     27               0.000000   \n",
       "4               1  0.158983                     27               0.033333   \n",
       "...           ...       ...                    ...                    ...   \n",
       "79325           0  0.036566                     35               0.966667   \n",
       "79326           0  0.162162                     35               1.000000   \n",
       "79327           0  0.054054                     35               1.000000   \n",
       "79328           0  0.173291                     35               1.000000   \n",
       "79329           0  0.325914                     35               0.933333   \n",
       "\n",
       "       StaysInWeekendNights  StaysInWeekNights  Adults  Children  Babies  \\\n",
       "0                     0.000           0.048780    0.25       0.0     0.0   \n",
       "1                     0.000           0.097561    0.50       0.0     0.0   \n",
       "2                     0.000           0.097561    0.25       0.0     0.0   \n",
       "3                     0.125           0.097561    0.50       0.0     0.0   \n",
       "4                     0.000           0.048780    0.50       0.0     0.0   \n",
       "...                     ...                ...     ...       ...     ...   \n",
       "79325                 0.125           0.121951    0.50       0.0     0.0   \n",
       "79326                 0.125           0.121951    0.75       0.0     0.0   \n",
       "79327                 0.125           0.121951    0.50       0.0     0.0   \n",
       "79328                 0.125           0.121951    0.50       0.0     0.0   \n",
       "79329                 0.125           0.170732    0.50       0.0     0.0   \n",
       "\n",
       "       PreviousCancellations  ...  x5_HB         x5_SC         x6_1  \\\n",
       "0                        0.0  ...           1.0           0.0   0.0   \n",
       "1                        0.0  ...           0.0           0.0   0.0   \n",
       "2                        0.0  ...           0.0           0.0   0.0   \n",
       "3                        0.0  ...           0.0           0.0   0.0   \n",
       "4                        0.0  ...           0.0           0.0   0.0   \n",
       "...                      ...  ...           ...           ...   ...   \n",
       "79325                    0.0  ...           0.0           0.0   0.0   \n",
       "79326                    0.0  ...           0.0           0.0   0.0   \n",
       "79327                    0.0  ...           0.0           0.0   0.0   \n",
       "79328                    0.0  ...           0.0           0.0   0.0   \n",
       "79329                    0.0  ...           1.0           0.0   0.0   \n",
       "\n",
       "       x7_B                 x7_C                 x7_D                 \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "79325                  0.0                  0.0                  0.0   \n",
       "79326                  0.0                  0.0                  0.0   \n",
       "79327                  0.0                  0.0                  1.0   \n",
       "79328                  0.0                  0.0                  0.0   \n",
       "79329                  0.0                  0.0                  0.0   \n",
       "\n",
       "       x7_E                 x7_F                 x7_G                 \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "79325                  0.0                  0.0                  0.0   \n",
       "79326                  1.0                  0.0                  0.0   \n",
       "79327                  0.0                  0.0                  0.0   \n",
       "79328                  0.0                  0.0                  0.0   \n",
       "79329                  0.0                  0.0                  0.0   \n",
       "\n",
       "       x7_P                 \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "...                    ...  \n",
       "79325                  0.0  \n",
       "79326                  0.0  \n",
       "79327                  0.0  \n",
       "79328                  0.0  \n",
       "79329                  0.0  \n",
       "\n",
       "[79330 rows x 207 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minmax_X = pd.read_csv(\"H2_preprocessdone.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "df_minmax_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLIT TRAIN_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"IsCanceled\"]\n",
    "features= df_minmax_X.columns.drop(target).to_list()\n",
    "data =df_minmax_X[features]\n",
    "target= df_minmax_X[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=target\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size = 0.25,\n",
    "                                                  random_state = 15,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Classification</font> <a class=\"anchor\" id=\"nineth-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function that will print the results of the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = list()\n",
    "resample = list()\n",
    "F1score_0 = list()\n",
    "F1score_1 = list()\n",
    "F1score_total = list()\n",
    "precision = list()\n",
    "AUCROC = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(Clf_model, X_test, y_test, algo=None, sampling=None):\n",
    "    # Test set prediction\n",
    "    y_prob = Clf_model.predict_proba(X_test)\n",
    "    y_pred = Clf_model.predict(X_test)\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print('='*60)\n",
    "    print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print('='*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\") #, labels=[0,1]\n",
    "    print('AUC-ROC')\n",
    "    print('='*60)\n",
    "    print(roc_auc_score(y_test, y_prob[:,1]))\n",
    "          \n",
    "    model.append(algo)\n",
    "    resample.append(sampling)\n",
    "    F1score_0.append(f1_score(y_test, y_pred, average='micro', labels=[0]))\n",
    "    F1score_1.append(f1_score(y_test, y_pred, average='micro', labels=[1]))\n",
    "    F1score_total.append(f1_score(y_test,y_pred, average='micro'))\n",
    "    precision.append(precision_score(y_test,y_pred))\n",
    "    AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Apply the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_score of the Random Forest is: 0.8637967981847977\n",
      "Confusion Matrix\n",
      "============================================================\n",
      "[[8530  716]\n",
      " [1445 5175]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      9246\n",
      "           1       0.88      0.78      0.83      6620\n",
      "\n",
      "    accuracy                           0.86     15866\n",
      "   macro avg       0.87      0.85      0.86     15866\n",
      "weighted avg       0.86      0.86      0.86     15866\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.9385302078860916\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "RF0 = RandomForestClassifier()\n",
    "RF0.fit(X_train, y_train)\n",
    "y_pred_RF = RF0.predict(X_val)\n",
    "f1_score_RF = f1_score(y_val, y_pred_RF, average='micro')\n",
    "print('The f1_score of the Random Forest is:', f1_score_RF)\n",
    "test_eval(RF0, X_val, y_val, 'Random Forest', sampling=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Apply the Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_score of the Gradient Boosting is: 0.8228286902811043\n",
      "Confusion Matrix\n",
      "============================================================\n",
      "[[8274  972]\n",
      " [1839 4781]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      9246\n",
      "           1       0.83      0.72      0.77      6620\n",
      "\n",
      "    accuracy                           0.82     15866\n",
      "   macro avg       0.82      0.81      0.81     15866\n",
      "weighted avg       0.82      0.82      0.82     15866\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.9066276230825382\n"
     ]
    }
   ],
   "source": [
    "GB0 = GradientBoostingClassifier(random_state = 5)\n",
    "GB0.fit(X_train, y_train)\n",
    "y_pred_GB = GB0.predict(X_val)\n",
    "f1_score_GB = f1_score(y_val, y_pred_GB, average='micro')\n",
    "print('The f1_score of the Gradient Boosting is:', f1_score_GB)\n",
    "test_eval(GB0, X_val, y_val, \"Gradient Boosting\", sampling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Feature Selection</font> <a class=\"anchor\" id=\"tenth-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance GB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_GB = pd.DataFrame({'feature':X_val.columns,'importance':np.round(GB0.feature_importances_,3)})\n",
    "importances_GB = importances_GB.sort_values('importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_RF = pd.DataFrame({'feature':X_val.columns,'importance':np.round(RF0.feature_importances_,3)})\n",
    "importances_RF = importances_RF.sort_values('importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected_RF = importances_RF[(importances_RF['importance']> 0.002)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected_GB = importances_GB[(importances_GB['importance']> 0.002)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_selected = set(list(features_selected_GB['feature']) + list(features_selected_RF['feature']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Ballancing Dataset</font> <a class=\"anchor\" id=\"eleventh-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample to balance the dataset with SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected_1 = ['Adults','ArrivalDateDayOfMonth','ArrivalDateWeekNumber','BookingChanges','Children','DaysInWaitingList','LeadTime',\\\n",
    "'PreviousBookingsNotCanceled','PreviousCancellations','RequiredCarParkingSpaces','StaysInWeekNights','StaysInWeekendNights',\\\n",
    "'TotalOfSpecialRequests','x0_AUT','x0_BEL','x0_BRA','x0_CHE','x0_CHN','x0_DEU','x0_ESP','x0_FRA','x0_GBR','x0_ITA','x0_PRT',\\\n",
    "'x0_USA','x1_Transient','x1_Transient-Party','x2_Non Refund     ','x3_Direct','x3_TA/TO','x4_Corporate','x4_Direct',\\\n",
    "'x4_Groups','x4_Offline TA/TO','x4_Online TA','x5_HB       ','x5_SC       ','x6_1','x7_D               ','x7_E               ','x7_F               '] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the range of categorical feature\n",
    "cat_indices1 = list(range(13,X_train.shape[1]))\n",
    "#apply smotenc for the dataset\n",
    "sm = SMOTENC(random_state=5, categorical_features=cat_indices1, k_neighbors=14)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "# print the original and resampled dataset\n",
    "print('Original dataset samples per class {}'.format(Counter(y_train['IsCanceled'])))\n",
    "print('Resampled dataset samples per class {}'.format(Counter(y_train_res['IsCanceled'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Apply the Random Forest Classifier with ballanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train_res[features_selected_1], y_train_res)\n",
    "y_pred_RF = RF.predict(X_val[features_selected_1])\n",
    "f1_score_RF = f1_score(y_val, y_pred_RF, average='micro')\n",
    "print('The f1_score of the Random Forest is:', f1_score_RF)\n",
    "test_eval(RF, X_val[features_selected_1], y_val, 'Random Forest', sampling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Apply the Gradient Boost Classifier with ballanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(random_state = 5)\n",
    "GB.fit(X_train_res[features_selected_1], y_train_res)\n",
    "y_pred_GB = GB.predict(X_val[features_selected_1])\n",
    "f1_score_GB = f1_score(y_val, y_pred_GB, average='micro')\n",
    "print('The f1_score of the Gradient Boosting is:', f1_score_GB)\n",
    "test_eval(GB, X_val[features_selected_1], y_val, \"Gradient Boosting\", sampling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Tuning Models</font> <a class=\"anchor\" id=\"twelveth-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Tuning Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_depths_tuning(train_sample, y_train_sample, x_val_sample, y_val_sample, list_max_depths):\n",
    "    max_depths  = list_max_depths #, 0.1, 0.05, 0.01]\n",
    "    train_results = []\n",
    "    val_results = []\n",
    "    for max_depth in max_depths:\n",
    "        RF = RandomForestClassifier(max_depth=max_depth)\n",
    "        RF.fit(train_sample, y_train_sample)\n",
    "        train_pred = RF.predict(train_sample)\n",
    "        f1_score_ = f1_score(y_train_sample, train_pred)\n",
    "        train_results.append(f1_score_)\n",
    "        y_pred = RF.predict(x_val_sample)\n",
    "        f1_score_ = f1_score(y_val_sample, y_pred)\n",
    "        val_results.append(f1_score_)\n",
    "    from matplotlib.legend_handler import HandlerLine2D\n",
    "    line1, = plt.plot(max_depths, train_results, \"b\", label=\"Train f1_score\")\n",
    "    line2, = plt.plot(max_depths, val_results, \"r\", label=\"val f1_score\")\n",
    "    plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "    plt.ylabel(\"f1 score\")\n",
    "    plt.xlabel(\"Max depths\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(13, 17, 5, endpoint=True)\n",
    "max_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths_tuning(X_train_res[features_selected_1], y_train_res, X_val[features_selected_1], y_val, max_depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_samples_tuning(train_sample, y_train_sample, x_val_sample, y_val_sample, list_nr_samples):\n",
    "    nr_samples = list_nr_samples#np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "    train_results = []\n",
    "    val_results = []\n",
    "    for nr_sample in nr_samples:\n",
    "        RF = RandomForestClassifier(min_samples_split=nr_sample)\n",
    "        RF.fit(train_sample, y_train_sample)\n",
    "        train_pred = RF.predict(train_sample)\n",
    "        f1_score_ = f1_score(y_train_sample, train_pred)\n",
    "        train_results.append(f1_score_)\n",
    "        y_pred = RF.predict(x_val_sample)\n",
    "        f1_score_ = f1_score(y_val_sample, y_pred)\n",
    "        val_results.append(f1_score_)\n",
    "    from matplotlib.legend_handler import HandlerLine2D\n",
    "    line1, = plt.plot(nr_samples, train_results, \"b\", label=\"Train f1_score\")\n",
    "    line2, = plt.plot(nr_samples, val_results, \"r\", label=\"val f1_score\")\n",
    "    plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "    plt.ylabel(\"f1 score\")\n",
    "    plt.xlabel(\"nr_samples\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mim= np.linspace(0.1, 0.6, 8, endpoint=True)\n",
    "mim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_samples_tuning(X_train_res[features_selected_1], y_train_res, X_val[features_selected_1], y_val, mim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_estimators_tuning(train_sample, y_train_sample, x_val_sample, y_val_sample, list_n_estimators):\n",
    "    n_estimators = list_n_estimators\n",
    "    train_results = []\n",
    "    val_results = []\n",
    "    for n_estimator in n_estimators:\n",
    "        RF = RandomForestClassifier(n_estimators=n_estimator)\n",
    "        RF.fit(train_sample, y_train_sample)\n",
    "        train_pred = RF.predict(train_sample)\n",
    "        f1_score_ = f1_score(y_train_sample, train_pred)\n",
    "        train_results.append(f1_score_)\n",
    "        y_pred = RF.predict(x_val_sample)\n",
    "        f1_score_ = f1_score(y_val_sample, y_pred)\n",
    "        val_results.append(f1_score_)\n",
    "    from matplotlib.legend_handler import HandlerLine2D\n",
    "    line1, = plt.plot(n_estimators, train_results, \"b\", label=\"Train f1_score\")\n",
    "    line2, = plt.plot(n_estimators, val_results, \"r\", label=\"val f1_score\")\n",
    "    plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "    plt.ylabel(\"f1 score\")\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=list(range(1,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-e03e04d34564>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_estimators_tuning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_selected_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_selected_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-257df521bacb>\u001b[0m in \u001b[0;36mn_estimators_tuning\u001b[1;34m(train_sample, y_train_sample, x_val_sample, y_val_sample, list_n_estimators)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_estimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mRF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mf1_score_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimators_tuning(X_train_res[features_selected_1], y_train_res, X_val[features_selected_1], y_val, n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters combination Random Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 200 candidates, totalling 3000 fits\n"
     ]
    }
   ],
   "source": [
    "#Random Hyperparameter Grid\n",
    "#n_estimators = list(range(1,50))\n",
    "#max_features = ['sqrt', 'log2']\n",
    "max_depth = np.linspace(13, 17, 5, endpoint=True)\n",
    "#min_samples_split = np.linspace(0.1, 0.6, 8, endpoint=True)\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True,False]\n",
    "#max_samples = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               #'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               #'min_samples_split': min_samples_split,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               #'max_samples': max_samples,\n",
    "               'bootstrap': bootstrap}\n",
    "RF = RandomForestClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "RF_best = RandomizedSearchCV(estimator = RF, param_distributions = random_grid,\\\n",
    "                        n_iter = 200, cv = cv, scoring='f1_micro', verbose=2, random_state=42, n_jobs = -1)\n",
    "RF_best.fit(X_train_res[features_selected_1], y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameter for the model\n",
    "RF_best.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF_best = RF_best.predict(X_train_res[features_selected_1])\n",
    "f1_score_RF_best = f1_score(y_train_res, y_pred_RF_best, average='micro')\n",
    "print('The f1_score of the Best Random Forest is:', f1_score_RF_best)\n",
    "test_eval(RF_best, X_val[features_selected_1], y_val, 'Random Forest', 'SMOTENC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Testing the Model</font> <a class=\"anchor\" id=\"fourteenth-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_val data by applying the scale obtained in the first command\n",
    "min_max_X_test = min_max.transform(X_test[integer_variables_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataframe with the scaled features\n",
    "X_test[integer_variables_1] = min_max_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(RF, X_test[features_selected_1], y_test, 'Random Forest', sampling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Lift Curves</font> <a class=\"anchor\" id=\"fifteenth-bullet\"></a>\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot lift curves Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lift curves\n",
    "predicted_probas = RF.predict_proba(X_test[features_selected_1])\n",
    "\n",
    "# figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 9))\n",
    "plot_cumulative_gain(y_test, predicted_probas, ax=ax1)\n",
    "plot_lift_curve(y_test, predicted_probas, ax=ax2)  # Lift is a measure of the effectiveness of a predictive model\n",
    "                                                   # calculated as the ratio between the results obtained with and \n",
    "                                                   # without the predictive model.\n",
    "# properties\n",
    "ax2.set_xlim(0.05, 1)\n",
    "ax2.set_xticks([0.05, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax2.set_xticklabels([0.05, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "for ax in (ax1, ax2):\n",
    "    ax.axes.lines[0].remove()\n",
    "    ax.get_legend().remove()\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
